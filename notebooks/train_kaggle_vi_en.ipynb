{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ Vietnamese-English Translation Model Training\n",
                "\n",
                "**Transformer-based Neural Machine Translation: VI ‚Üí EN**\n",
                "\n",
                "This notebook trains a **REVERSED** translation model:\n",
                "- **Source**: Vietnamese üáªüá≥\n",
                "- **Target**: English üá¨üáß\n",
                "\n",
                "Using:\n",
                "- **PhoMT Dataset** (~3M sentence pairs)\n",
                "- **Modern Transformer** with RMSNorm, SwiGLU, RoPE\n",
                "- **AdamW + Cosine Annealing Warm Restarts**\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ‚öôÔ∏è Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone repository\n",
                "!git clone https://github.com/TranKien2005/EV_Translate_Modle_NLP_Project.git\n",
                "%cd EV_Translate_Modle_NLP_Project"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q datasets sentencepiece sacrebleu google-generativeai python-dotenv tqdm tensorboard seaborn pyyaml"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify PyTorch and CUDA\n",
                "import torch\n",
                "print(f'PyTorch version: {torch.__version__}')\n",
                "print(f'CUDA available: {torch.cuda.is_available()}')\n",
                "if torch.cuda.is_available():\n",
                "    print(f'CUDA device: {torch.cuda.get_device_name(0)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create .env file with API keys\n",
                "GEMINI_API_KEY = \"YOUR_GEMINI_API_KEY_HERE\"\n",
                "HF_TOKEN = \"YOUR_HF_TOKEN_HERE\"\n",
                "\n",
                "with open('.env', 'w') as f:\n",
                "    f.write(f'GEMINI_API_KEY={GEMINI_API_KEY}\\n')\n",
                "    f.write(f'HF_TOKEN={HF_TOKEN}\\n')\n",
                "\n",
                "print('‚úì .env file created')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. üîß Configure Paths for Kaggle\n",
                "\n",
                "**IMPORTANT**: Update paths in config file for Kaggle environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚ö†Ô∏è IMPORTANT: Configure paths for Kaggle\n",
                "# All paths are defined in ONE place: config YAML file\n",
                "\n",
                "import yaml\n",
                "\n",
                "CONFIG_FILE = 'config/config_vi_en.yaml'\n",
                "\n",
                "# Load config\n",
                "with open(CONFIG_FILE, 'r') as f:\n",
                "    cfg = yaml.safe_load(f)\n",
                "\n",
                "# Update paths for Kaggle\n",
                "cfg['paths'] = {\n",
                "    'data_dir': '/kaggle/working/data',\n",
                "    'checkpoint_dir': '/kaggle/working/checkpoints_vi_en',\n",
                "    'log_dir': '/kaggle/working/logs_vi_en'\n",
                "}\n",
                "\n",
                "# Save updated config\n",
                "with open(CONFIG_FILE, 'w') as f:\n",
                "    yaml.dump(cfg, f, default_flow_style=False, allow_unicode=True)\n",
                "\n",
                "print('‚úì Config paths updated for Kaggle:')\n",
                "print(f\"  data_dir: {cfg['paths']['data_dir']}\")\n",
                "print(f\"  checkpoint_dir: {cfg['paths']['checkpoint_dir']}\")\n",
                "print(f\"  log_dir: {cfg['paths']['log_dir']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. üì• Download & Preprocess Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create data directory\n",
                "!mkdir -p /kaggle/working/data\n",
                "\n",
                "# Download PhoMT dataset\n",
                "!python scripts/download_phomt.py"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preprocess data (train tokenizers + create .pt files)\n",
                "# ‚ö†Ô∏è Uses VI-EN config: Vietnamese as SOURCE, English as TARGET\n",
                "\n",
                "!python scripts/preprocess_data.py --config config/config_vi_en.yaml"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. üîç Configuration Check"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '.')\n",
                "\n",
                "from src.config import load_config\n",
                "from src.models import Transformer\n",
                "\n",
                "# Load VI-EN config\n",
                "config = load_config('config/config_vi_en.yaml')\n",
                "\n",
                "print(\"=\"*50)\n",
                "print(\"üìã Configuration Summary (VI ‚Üí EN)\")\n",
                "print(\"=\"*50)\n",
                "print(f\"\\nüîπ Paths:\")\n",
                "print(f\"   data_dir: {config.paths.data_dir}\")\n",
                "print(f\"   checkpoint_dir: {config.paths.checkpoint_dir}\")\n",
                "print(f\"\\nüîπ Model:\")\n",
                "print(f\"   d_model: {config.d_model}\")\n",
                "print(f\"   layers: {config.num_encoder_layers} enc + {config.num_decoder_layers} dec\")\n",
                "print(f\"   d_ff: {config.d_ff}\")\n",
                "print(f\"\\nüîπ Training:\")\n",
                "print(f\"   epochs: {config.epochs}\")\n",
                "print(f\"   batch_size: {config.batch_size}\")\n",
                "print(f\"   learning_rate: {config.learning_rate}\")\n",
                "print(f\"   warmup_steps: {config.warmup_steps}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Count model parameters\n",
                "model = Transformer(\n",
                "    src_vocab_size=config.src_vocab_size,\n",
                "    tgt_vocab_size=config.tgt_vocab_size,\n",
                "    d_model=config.d_model,\n",
                "    num_heads=config.num_heads,\n",
                "    num_encoder_layers=config.num_encoder_layers,\n",
                "    num_decoder_layers=config.num_decoder_layers,\n",
                "    d_ff=config.d_ff\n",
                ")\n",
                "\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "print(f\"\\nüìä Model Parameters: {total_params:,} ({total_params/1e6:.1f}M)\")\n",
                "print(f\"üì¶ Model Size: ~{total_params * 4 / 1024 / 1024:.1f} MB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. üèãÔ∏è Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Switch to processed data for faster training\n",
                "import yaml\n",
                "\n",
                "with open('config/config_vi_en.yaml', 'r') as f:\n",
                "    cfg = yaml.safe_load(f)\n",
                "\n",
                "cfg['data']['source'] = 'processed'\n",
                "\n",
                "with open('config/config_vi_en.yaml', 'w') as f:\n",
                "    yaml.dump(cfg, f, default_flow_style=False, allow_unicode=True)\n",
                "\n",
                "print('‚úì Config updated to use processed data')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Start training!\n",
                "from src.train import Trainer\n",
                "\n",
                "trainer = Trainer(config_path='config/config_vi_en.yaml')\n",
                "trainer.setup()\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"üáªüá≥ ‚Üí üá¨üáß Vietnamese to English Translation\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "print(\"\\nüöÄ Starting training from scratch\")\n",
                "trainer.train()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìù Notes\n",
                "\n",
                "**Model Info (VI ‚Üí EN):**\n",
                "- Architecture: Modern Transformer (SwiGLU, RMSNorm, RoPE)\n",
                "- Direction: Vietnamese ‚Üí English\n",
                "- Scheduler: Cosine Annealing with Warm Restarts\n",
                "\n",
                "**Output Files:**\n",
                "- Checkpoints: `/kaggle/working/checkpoints_vi_en/`\n",
                "- Best model: `best_model.pt`\n",
                "- Tokenizers: `tokenizers/tokenizer_vi.model`, `tokenizers/tokenizer_en.model`"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}