{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üîÑ Resume Training: VI ‚Üí EN\n",
                "\n",
                "Ti·∫øp t·ª•c training t·ª´ checkpoint.\n",
                "\n",
                "**Upload v√†o Kaggle Input:**\n",
                "- `best_model.pt` (checkpoint)\n",
                "- `tokenizer_vi.model`\n",
                "- `tokenizer_en.model`\n",
                "- `train.pt` (processed data)\n",
                "- `val.pt` (processed data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!git clone https://github.com/TranKien2005/EV_Translate_Modle_NLP_Project.git\n",
                "%cd EV_Translate_Modle_NLP_Project\n",
                "!pip install -q sentencepiece sacrebleu google-generativeai python-dotenv tqdm tensorboard pyyaml"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')\n",
                "if torch.cuda.is_available(): print(f'GPU: {torch.cuda.get_device_name(0)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "GEMINI_API_KEY = \"YOUR_GEMINI_API_KEY\"\n",
                "HF_TOKEN = \"YOUR_HF_TOKEN\"\n",
                "\n",
                "with open('.env', 'w') as f:\n",
                "    f.write(f'GEMINI_API_KEY={GEMINI_API_KEY}\\nHF_TOKEN={HF_TOKEN}\\n')\n",
                "print('‚úì .env created')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ========================================\n",
                "# üëá NH·∫¨P ƒê∆Ø·ªúNG D·∫™N T·∫†I ƒê√ÇY üëá\n",
                "# ========================================\n",
                "\n",
                "CHECKPOINT_PATH = \"\"      # /kaggle/input/.../best_model.pt\n",
                "TOKENIZER_VI_PATH = \"\"    # /kaggle/input/.../tokenizer_vi.model\n",
                "TOKENIZER_EN_PATH = \"\"    # /kaggle/input/.../tokenizer_en.model\n",
                "TRAIN_PT_PATH = \"\"        # /kaggle/input/.../train.pt\n",
                "VAL_PT_PATH = \"\"          # /kaggle/input/.../val.pt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import shutil\n",
                "from pathlib import Path\n",
                "\n",
                "# Add project to path\n",
                "sys.path.insert(0, '.')\n",
                "\n",
                "# Validate input files\n",
                "for name, path in [('Checkpoint', CHECKPOINT_PATH), ('Tokenizer VI', TOKENIZER_VI_PATH), \n",
                "                   ('Tokenizer EN', TOKENIZER_EN_PATH), ('Train.pt', TRAIN_PT_PATH), \n",
                "                   ('Val.pt', VAL_PT_PATH)]:\n",
                "    assert path and os.path.exists(path), f\"{name} not found: {path}\"\n",
                "    print(f'‚úì {name}: {path}')\n",
                "\n",
                "# Load config to get correct paths\n",
                "from src.config import load_config\n",
                "config = load_config('config/config_vi_en.yaml')\n",
                "\n",
                "# Get actual paths from config\n",
                "checkpoint_dir = config.paths.checkpoint_dir\n",
                "data_dir = config.paths.data_dir\n",
                "\n",
                "print(f'\\nüìç Config paths:')\n",
                "print(f'   checkpoint_dir: {checkpoint_dir}')\n",
                "print(f'   data_dir: {data_dir}')\n",
                "\n",
                "# Copy tokenizers to config's checkpoint_dir\n",
                "tok_dir = checkpoint_dir / 'tokenizers'\n",
                "tok_dir.mkdir(parents=True, exist_ok=True)\n",
                "shutil.copy(TOKENIZER_VI_PATH, tok_dir / 'tokenizer_vi.model')\n",
                "shutil.copy(TOKENIZER_EN_PATH, tok_dir / 'tokenizer_en.model')\n",
                "print(f'\\n‚úì Tokenizers ‚Üí {tok_dir}')\n",
                "\n",
                "# Copy processed data to config's data_dir\n",
                "processed_dir = data_dir / 'processed_vi_en'\n",
                "processed_dir.mkdir(parents=True, exist_ok=True)\n",
                "shutil.copy(TRAIN_PT_PATH, processed_dir / 'train.pt')\n",
                "shutil.copy(VAL_PT_PATH, processed_dir / 'val.pt')\n",
                "print(f'‚úì Processed data ‚Üí {processed_dir}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Config: use processed data\n",
                "import yaml\n",
                "\n",
                "with open('config/config_vi_en.yaml', 'r') as f:\n",
                "    cfg = yaml.safe_load(f)\n",
                "\n",
                "cfg['data']['source'] = 'processed'\n",
                "\n",
                "with open('config/config_vi_en.yaml', 'w') as f:\n",
                "    yaml.dump(cfg, f, default_flow_style=False)\n",
                "\n",
                "print('‚úì Config: source = processed')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.train import Trainer\n",
                "\n",
                "trainer = Trainer(config_path='config/config_vi_en.yaml')\n",
                "trainer.setup()\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"üîÑ Resuming VI ‚Üí EN Training\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "trainer.train(resume_from=CHECKPOINT_PATH)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}