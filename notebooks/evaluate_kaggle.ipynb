{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìä Evaluate English-Vietnamese Model\n",
                "\n",
                "Evaluate and test the EN ‚Üí VI translation model.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ‚öôÔ∏è Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!git clone https://github.com/TranKien2005/EV_Translate_Modle_NLP_Project.git\n",
                "%cd EV_Translate_Modle_NLP_Project"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q sentencepiece sacrebleu google-generativeai python-dotenv tqdm pyyaml"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "GEMINI_API_KEY = \"YOUR_GEMINI_API_KEY_HERE\"\n",
                "\n",
                "with open('.env', 'w') as f:\n",
                "    f.write(f'GEMINI_API_KEY={GEMINI_API_KEY}\\n')\n",
                "print('‚úì .env created')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. üîß Configure Paths"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import yaml\n",
                "\n",
                "KAGGLE_INPUT_MODEL = '/kaggle/input/en-vi-model'  # CHANGE THIS\n",
                "\n",
                "CONFIG_FILE = 'config/config.yaml'\n",
                "\n",
                "with open(CONFIG_FILE, 'r') as f:\n",
                "    cfg = yaml.safe_load(f)\n",
                "\n",
                "cfg['paths'] = {\n",
                "    'data_dir': '/kaggle/working/data',\n",
                "    'checkpoint_dir': '/kaggle/working/checkpoints',\n",
                "    'log_dir': '/kaggle/working/logs'\n",
                "}\n",
                "\n",
                "with open(CONFIG_FILE, 'w') as f:\n",
                "    yaml.dump(cfg, f, default_flow_style=False, allow_unicode=True)\n",
                "\n",
                "print('‚úì Config paths updated')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil\n",
                "\n",
                "!mkdir -p /kaggle/working/checkpoints/tokenizers\n",
                "\n",
                "shutil.copy(f'{KAGGLE_INPUT_MODEL}/best_model.pt', '/kaggle/working/checkpoints/best_model.pt')\n",
                "shutil.copy(f'{KAGGLE_INPUT_MODEL}/tokenizer_en.model', '/kaggle/working/checkpoints/tokenizers/tokenizer_en.model')\n",
                "shutil.copy(f'{KAGGLE_INPUT_MODEL}/tokenizer_vi.model', '/kaggle/working/checkpoints/tokenizers/tokenizer_vi.model')\n",
                "\n",
                "print('‚úì Model files copied')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. üì• Load Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '.')\n",
                "\n",
                "from src.evaluate import load_translator\n",
                "from src.config import load_config\n",
                "\n",
                "config = load_config('config/config.yaml')\n",
                "\n",
                "translator = load_translator(\n",
                "    checkpoint_path=str(config.paths.checkpoint_dir / 'best_model.pt'),\n",
                "    vocab_src_path=str(config.paths.checkpoint_dir / 'tokenizers/tokenizer_en.model'),\n",
                "    vocab_tgt_path=str(config.paths.checkpoint_dir / 'tokenizers/tokenizer_vi.model'),\n",
                "    config_path='config/config.yaml'\n",
                ")\n",
                "\n",
                "print('‚úì Translator loaded')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. üß™ Test Translations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_sentences = [\n",
                "    \"Hello, how are you?\",\n",
                "    \"I love Vietnam.\",\n",
                "    \"The weather is beautiful today.\",\n",
                "    \"Thank you very much.\",\n",
                "    \"I am learning Vietnamese.\"\n",
                "]\n",
                "\n",
                "print(\"üá¨üáß ‚Üí üáªüá≥ English to Vietnamese Translations\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "for en in test_sentences:\n",
                "    vi = translator.translate(en)\n",
                "    print(f\"\\nEN: {en}\")\n",
                "    print(f\"VI: {vi}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}