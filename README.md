# üåê Vietnamese-English Translation Model

Transformer-based Neural Machine Translation for Vietnamese ‚Üî English.

## ‚ú® Features

- **VI ‚Üí EN**: Vietnamese to English translation
- **EN ‚Üí VI**: English to Vietnamese translation
- **Transformer architecture**: 6 encoder + 5 decoder layers
- **SentencePiece BPE tokenizer**: 16k vocabulary

## üöÄ Quick Start

### Installation

```bash
git clone https://github.com/TranKien2005/EV_Translate_Modle_NLP_Project.git
cd EV_Translate_Modle_NLP_Project
pip install torch sentencepiece sacrebleu google-generativeai python-dotenv tqdm pyyaml tensorboard
```

### API Keys (Required for full features)

Create `.env` file in project root:
```bash
GEMINI_API_KEY=your_gemini_api_key    # For Gemini evaluation
HF_TOKEN=your_huggingface_token       # For dataset download
```

- **GEMINI_API_KEY**: Get from [Google AI Studio](https://makersuite.google.com/app/apikey)
- **HF_TOKEN**: Get from [HuggingFace Settings](https://huggingface.co/settings/tokens)

### Translation

```python
from src.evaluate import load_translator

# VI ‚Üí EN
translator = load_translator(
    checkpoint_path='checkpoints_vi_en/best_model.pt',
    vocab_src_path='checkpoints_vi_en/tokenizers/tokenizer_vi.model',
    vocab_tgt_path='checkpoints_vi_en/tokenizers/tokenizer_en.model',
    config_path='config/config_vi_en.yaml'
)

result = translator.translate("Xin ch√†o, b·∫°n kh·ªèe kh√¥ng?")
print(result)  # Hello, how are you?
```

## üèãÔ∏è Training

### On Kaggle (Recommended)
1. Upload notebook `notebooks/train_kaggle_vi_en.ipynb` to Kaggle
2. Enable GPU accelerator
3. Run all cells

### Resume Training
1. Upload checkpoint + tokenizers + processed data
2. Use `notebooks/train_kaggle_vi_en_resume.ipynb`

### Local Training

**1. Download dataset:**
```bash
python scripts/download_phomt.py
```

**2. Preprocess data:**
```bash
# For VI ‚Üí EN
python scripts/preprocess_data.py --config config/config_vi_en.yaml

# For EN ‚Üí VI
python scripts/preprocess_data.py --config config/config.yaml
```

**3. Train:**
```bash
python -m src.train --config config/config_vi_en.yaml
```

## ‚öôÔ∏è Configuration

### Config Files

| File | Direction | Description |
|------|-----------|-------------|
| `config/config.yaml` | EN ‚Üí VI | English to Vietnamese |
| `config/config_vi_en.yaml` | VI ‚Üí EN | Vietnamese to English |

### Key Parameters

```yaml
# Model
model:
  d_model: 512              # Model dimension
  num_heads: 8              # Attention heads
  num_encoder_layers: 6     # Encoder depth
  num_decoder_layers: 5     # Decoder depth

# Training
training:
  batch_size: 64            # Batch size per GPU
  gradient_accumulation_steps: 2  # Effective batch = 128
  learning_rate: 0.0005     # Initial learning rate
  epochs: 15                # Training epochs
  warmup_steps: 2000        # LR warmup steps

# Data
data:
  source: "local"           # "local", "huggingface", or "processed"
  max_seq_len: 128          # Maximum sequence length
```

### Override Config via CLI
```bash
# Change batch size
python -m src.train --config config/config_vi_en.yaml --batch_size 32

# Change learning rate
python -m src.train --config config/config_vi_en.yaml --learning_rate 0.0003
```

## üîß Scripts

| Script | Description |
|--------|-------------|
| `scripts/download_phomt.py` | Download PhoMT dataset from HuggingFace |
| `scripts/preprocess_data.py` | Tokenize and prepare training data |

### Preprocess Options
```bash
python scripts/preprocess_data.py --help

# Options:
#   --config PATH       Config file (default: config/config.yaml)
#   --max-samples N     Limit samples for testing
#   --force-retrain     Retrain tokenizers even if exists
```

## ÔøΩ Evaluation

### BLEU Score
```bash
python -m src.evaluate \
    --config config/config_vi_en.yaml \
    --checkpoint checkpoints_vi_en/best_model.pt
```

### Gemini Evaluation (requires GEMINI_API_KEY)
```bash
python -m src.evaluate \
    --config config/config_vi_en.yaml \
    --checkpoint checkpoints_vi_en/best_model.pt \
    --gemini
```

### Interactive Translation
```bash
python -m src.evaluate \
    --config config/config_vi_en.yaml \
    --checkpoint checkpoints_vi_en/best_model.pt \
    --interactive
```

## ÔøΩüìÅ Project Structure

```
‚îú‚îÄ‚îÄ config/          # Training configurations
‚îú‚îÄ‚îÄ notebooks/       # Kaggle training notebooks
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ models/      # Transformer model
‚îÇ   ‚îú‚îÄ‚îÄ data/        # Dataset & tokenizer
‚îÇ   ‚îî‚îÄ‚îÄ train.py     # Training script
‚îî‚îÄ‚îÄ scripts/         # Utility scripts
```

## üìÑ License

MIT License
